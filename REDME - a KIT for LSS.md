# Social Media Simulation Framework

## Overview

This framework simulates opinion dynamics on social media using LLM-powered agents. Agents with distinct political stances interact on a simulated social platform, posting content and engaging with others' posts around a controversial topic (currently the Ukraine war).

The simulation models realistic social media behavior: agents see posts from their network neighbors, decide whether to "like" them based on their personalities and values, and create their own posts either responding to others or sharing original thoughts. Over time, patterns emerge showing how different ranking algorithms influence discourse quality and opinion dynamics.

## How the Simulation Works

### Network Structure

Agents are arranged in a **Watts-Strogatz small-world network** - a topology that mimics real social networks with local clustering and occasional long-range connections. Each agent has a fixed number of neighbors (default: 4) and can only see posts from those neighbors.

### Agent Personalities

Each agent is initialized with:

- **Stance**: Pro-Russia, neutral, or pro-Ukraine (randomly assigned)
- **Name**: Randomly selected username

Agents maintain their stance throughout the simulation.

### Simulation Timesteps

The simulation runs in discrete timesteps. At each timestep:

1. **Ranking**: A weighted ranking algorithm determines which posts each agent sees from their network neighborhood
2. **Reading**: Each agent reads their top-k ranked posts (default: k=2)
3. **Liking**: Agents evaluate each post they read and decide whether to "like" it based on personality alignment
4. **Posting**: Each agent creates one new post, either replying to something they read or sharing an original thought

### Ranking Mechanisms

The system implements multiple ranking algorithms that can be compared:

- **Time decay**: Recent posts weighted higher than old posts
- **Agent success**: Posts from popular/successful agents weighted higher
- **Post success**: Individual posts with many likes weighted higher
- **Personal preference**: Posts from agents you've liked before weighted higher

These weights combine to determine which posts rise to the top of each agent's feed. Posts already read are filtered out. The ranking directly shapes what agents see and respond to, influencing the overall discourse.

### Data Tracking

The simulation captures comprehensive interaction data:

- **Posts**: Every message generated by every agent
- **Read history**: Which posts each agent read at each timestep
- **Likes**: Binary tracking of who liked what (old aggregate + new individual-level)
- **Conversation graphs**: Reply chains and discussion threads
- **Agent state**: Success scores, network connections, personal preferences

### Warmup Phase

Before the main simulation, agents go through a "thermalization" phase where they generate initial posts to establish their baseline positions. This warmup creates a starting corpus of content for agents to react to once the main simulation begins.

## Prompting Structure

The framework uses structured prompts with clear role separation:

### System Message

Contains the agent's persona and stable behavioral rules loaded from `prompts.yaml`. This establishes who the agent is and never changes during the simulation.

### User Message

Provides context and task instructions in a strict format with explicit boundaries:

```
CONTEXT START
[relevant information]

TASK:
[what to do]

OUTPUT FORMAT (STRICT):
[exact format expected]
CONTEXT END
```

### Example: Liking Prompt

**System:**

```
You are a social media user who is strongly pro-Ukraine. 
You are living in Europe, and talking in English.
NEVER BREAK CHARACTER.
You will rate how much you like another user's message.
Base your judgment on how well the message aligns with 
your personality, values, and prior posts.
Respond ONLY with a single digit between 0 and 9 
(0 = strongly dislike, 9 = strongly like).
```

**User:**

```
CONTEXT START
YOUR RECENT POSTS:
you: Russia's invasion violates international law
you: Ukraine deserves full Western support
you: Putin must be held accountable

MESSAGE TO RATE:
@user47: NATO expansion provoked this conflict

TASK:
Evaluate how much you like this message given your 
personality and past posts.

OUTPUT FORMAT (STRICT):
RATING=<0-9>
CONTEXT END
```

### Example: Posting Prompt

**System:**

```
You are a social media user who is neutral. 
You are living in Europe, and talking in English.
NEVER BREAK CHARACTER.
Topic: the war in Ukraine.
Style: keep posts ≤ 3 sentences. You may reply to 
someone using @username or write an original post. 
Be concise, direct, and colloquial.
```

**User:**

```
CONTEXT START
READ_HISTORY:
@AlexT: Ukraine is winning the information war
@Sarah_M: Both sides have committed atrocities

YOUR_PREVIOUS_POSTS:
you: This conflict has deep historical roots
you: Peace negotiations need neutral mediators

TASK:
Write your next post NOW. Either reply to one of 
the above using @username, or write a new post if 
you prefer. Keep it ≤ 3 sentences.

OUTPUT FORMAT (STRICT):
Return ONLY the post text (no quotes, no preface).
CONTEXT END
```

The prompts enforce strict output contracts - agents must return exactly the format specified (single digit for likes, plain text for posts). This "glass cannon" approach makes debugging transparent: malformed outputs cause immediate crashes rather than silent fallbacks.

## Simulation Environment Architecture

### Core Components

**Graph Structure (`simulation.py`)**

- `G`: igraph Graph object representing the social network
- Agent attributes stored as vertex properties:
    - `neighbors`: NumPy array of neighbor IDs
    - `read_history`: 3D array `[T_total, posts_per_round, 2]` storing (author_id, timestep) pairs
    - `success`: Integer count of total likes received
    - `preferred_neighbors`: Array tracking interaction preferences
    - `lookout`: Reverse lookup indices for efficient neighbor operations
- Graph attributes:
    - `T_total`: Total timesteps (warmup + main simulation)
    - `T_current`: Current timestep index
    - `warmup_length`: Number of warmup timesteps

**Matrix Structures (`simulation.py`)**

- `WEIGHTS`: Shape `[num_agents, T_total, max_degree]` - ranking weights for each agent's view of each neighbor's posts
- `READ_MATRIX`: Shape `[num_agents, T_total, max_degree]` - binary matrix tracking which posts have been read
- `LIKES`: Shape `[num_agents, T_total]` - aggregate like counts per post (legacy format)
- `INDIVIDUAL_LIKES`: Shape `[num_agents, num_agents, T_total]` - binary tensor tracking exactly who liked what
- `POSTS`: Shape `[num_agents, T_total]` - object array storing post text

**Data Persistence (`save.py`)**

- Per-replica directories with:
    - `arrays.npz`: Compressed NumPy arrays (weights, reads, likes)
    - `posts.csv`: Flattened (agent, timestep, text) tuples
    - `graph_data.json`: Read history and agent metadata
    - `meta.json`: Shapes, parameters, run IDs
- `manifest.json`: Top-level index linking all replica outputs

### Execution Flow

**Initialization (`_initialize_everything`)**

1. Set random seed
2. Generate Watts-Strogatz network with `generate_network()`
3. Initialize all matrices with `_initialize_matrices()`
4. Build neighbor lookup tables with `_build_neighbor_lookups()`

**Agent Setup (`initialize_agents`)**

1. Load usernames from CSV
2. Assign random stance (0=pro-Russia, 1=neutral, 2=pro-Ukraine)
3. Load corresponding persona YAML
4. Pre-format system messages for warmup/likes/posts

**Thermalization (`thermalize_system`)**

1. Generate prompts for all agents for warmup timesteps
2. Batch execute with `_execute_prompts_with_coords()`
3. Populate initial posts in POSTS matrix

**Main Loop (per timestep)**

1. **`_matrix_operations()`**:
    
    - `_calculate_weights()`: Compute ranking weights with time decay, success, preferences
    - `_find_top_k_posts()`: Extract top-k posts per agent using argpartition
    - `_mark_posts_as_read()`: Update READ_MATRIX for selected posts
    - `_update_read_list()`: Store (author, timestep) pairs in agent read_history
2. **`evaluate_likes()`**:
    
    - Compose like prompts with `_compose_prompt_for_likes()`
    - Execute in batches via `_execute_prompts_with_coords()`
    - Parse digit responses and sample binary decisions
3. **`_update_likes_and_consequences()`**:
    
    - Increment LIKES counts for liked posts
    - Update agent success scores
    - Adjust preferred_neighbors weights
    - Mark INDIVIDUAL_LIKES[reader][author][timestep] = True
4. **`generate_posts()`**:
    
    - Compose post prompts with `_compose_prompt_for_posts()`
    - Execute in batches
    - Store generated text in POSTS[agent][T_current]

### Neighbor Lookup System

The framework maintains precomputed lookup tables for O(1) neighbor operations:

**`neighbor_lookup`**: 2D array `[num_agents, max_degree]` where `neighbor_lookup[i, j]` gives the j-th neighbor ID of agent i (or -1 if no such neighbor)

**`lookout_lookup`**: 2D array `[num_agents, max_degree]` where `lookout_lookup[i, j]` gives the reverse index - which position agent i occupies in the neighbor list of `neighbor_lookup[i, j]`

This bidirectional mapping enables:

- Fast iteration over an agent's neighbors
- Fast marking of posts as read from the neighbor's perspective
- Efficient weight updates based on personal preferences

Example: If agent 5's neighbors are [2, 7, 11], then:

- `neighbor_lookup[5, 0:3] = [2, 7, 11]`
- `lookout_lookup[5, 0] = k` where agent 2's neighbors[k] = 5

### Interface Pattern

The `interfaces.py` module provides async wrappers that dispatch to the appropriate opinion model implementation (LLM, BCM, Axelrod, etc.):

```python
async def initialize_agents(G, PARAMS):
    model = get_model(PARAMS["opinion_model"])
    func = model.initialize_agents
    if inspect.iscoroutinefunction(func):
        return await func(G, PARAMS)
    else:
        return func(G, PARAMS)
```

This allows seamless switching between synchronous mathematical models and async LLM-based models without changing simulation code.

### Batch Execution

LLM calls use batch execution with configurable parameters:

- `batch_size`: Number of prompts per batch (default: 512)
- `concurrency`: Parallel API requests (default: 64)
- Prompts chunked and processed sequentially by batch
- Coordinates tracked through execution to match responses back to agents

The vLLM executor (`vllm_offline.py`) maintains a global LLM instance that persists across batches within a replica to avoid costly reloading overhead.

### Parameter Configuration

`PARAMS.json` controls all simulation aspects:

- Network structure: `num_agents`, `neighbors`, `rewiring_p`
- Time: `timesteps`, `warmup_length`
- Ranking: `time_decay_rate`, `W_agent_success`, `W_post_success`, `W_personal_weights`
- Memory: `post_read_per_round`, `memory` (lookback window)
- Model: `opinion_model`, `MODEL`, `API_URL`
- Execution: `batch_size`, `concurrency`

Sensitive keys (tokens, API keys) are automatically filtered from saved outputs.